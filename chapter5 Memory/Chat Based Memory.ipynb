{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a helpful AI talking to a human\n",
      "Human: My name is Nico\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Nice to meet you, Nico! How can I assist you today?'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LangChain 라이브러리에서 필요한 구성요소를 임포트\n",
    "from langchain.memory import ConversationSummaryBufferMemory  # 대화 내역을 요약해서 저장하는 메모리 구성요소\n",
    "from langchain.chat_models import ChatOpenAI  # OpenAI의 채팅 모델을 사용해 응답 생성\n",
    "from langchain.chains import LLMChain  # 상호작용 구조를 정의하는 체인 구성요소\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder  # 프롬프트 관련 유틸리티\n",
    "\n",
    "# 낮은 온도로 OpenAI 채팅 모델 초기화 (결과를 더 일관되게 생성)\n",
    "llm = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "# 대화 내용을 저장하고 요약하는 메모리 객체 정의\n",
    "memory = ConversationSummaryBufferMemory(\n",
    "    llm=llm,  # 요약을 위해 같은 언어 모델 사용\n",
    "    max_token_limit=120,  # 메모리 크기를 120 토큰으로 제한\n",
    "    memory_key=\"chat_history\",  # 메모리에 대화 내역을 저장할 키 이름\n",
    "    return_messages=True,  # 요약 대신 메시지 형식으로 반환\n",
    ")\n",
    "\n",
    "# 상호작용을 위한 프롬프트 구조 정의\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful AI talking to a human\"),  # AI의 역할을 설정하는 시스템 메시지\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),  # 대화 내역이 들어갈 자리 표시자\n",
    "        (\"human\", \"{question}\"),  # 사용자의 질문이 들어갈 자리 표시자\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 메모리, 모델, 프롬프트를 결합한 체인 생성\n",
    "chain = LLMChain(\n",
    "    llm=llm,  # 응답 생성을 위해 사용할 언어 모델\n",
    "    memory=memory,  # 대화 내역을 추적하기 위한 메모리 객체\n",
    "    prompt=prompt,  # 입력 구조를 정의한 프롬프트\n",
    "    verbose=True,  # 디버깅 또는 상세 로그를 활성화\n",
    ")\n",
    "\n",
    "# 체인을 사용해 질문 \"My name is Nico\"에 대한 예측 수행\n",
    "chain.predict(question=\"My name is Nico\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a helpful AI talking to a human\n",
      "Human: My name is Nico\n",
      "AI: Nice to meet you, Nico! How can I assist you today?\n",
      "Human: I live in Seoul\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Seoul is a vibrant city with a rich history and culture. Is there anything specific you would like to know or discuss about Seoul?'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.predict(question=\"I live in Seoul\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a helpful AI talking to a human\n",
      "Human: My name is Nico\n",
      "AI: Nice to meet you, Nico! How can I assist you today?\n",
      "Human: I live in Seoul\n",
      "AI: Seoul is a vibrant city with a rich history and culture. Is there anything specific you would like to know or discuss about Seoul?\n",
      "Human: What is my name?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Your name is Nico. How can I assist you further, Nico?'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.predict(question=\"What is my name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
