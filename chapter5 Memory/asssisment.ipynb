{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for FewShotPromptTemplate\nexample_prompt\n  value is not a valid dict (type=type_error.dict)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 20\u001b[0m\n\u001b[0;32m     14\u001b[0m examples \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     15\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTop Gun\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mğŸ›©ï¸ğŸ‘¨â€âœˆï¸ğŸ”¥\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m     16\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe Godfather\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mğŸ‘¨â€ğŸ‘¨â€ğŸ‘¦ğŸ”«ğŸ\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m     17\u001b[0m ]\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# FewShotPromptTemplate ì •ì˜\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m few_shot_template \u001b[38;5;241m=\u001b[39m \u001b[43mFewShotPromptTemplate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexamples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexamples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_variables\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# ì‚¬ìš©í•  ì…ë ¥ ë³€ìˆ˜ ì •ì˜\u001b[39;49;00m\n\u001b[0;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexample_prompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{input}\u001b[39;49;00m\u001b[38;5;124;43m: \u001b[39;49m\u001b[38;5;132;43;01m{output}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43msuffix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mInput: \u001b[39;49m\u001b[38;5;132;43;01m{input}\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mOutput:\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m     25\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# ConversationChain ìƒì„±\u001b[39;00m\n\u001b[0;32m     28\u001b[0m chain \u001b[38;5;241m=\u001b[39m ConversationChain(\n\u001b[0;32m     29\u001b[0m     llm\u001b[38;5;241m=\u001b[39mllm,  \u001b[38;5;66;03m# ì ì ˆí•œ LLM ì—°ê²°\u001b[39;00m\n\u001b[0;32m     30\u001b[0m     prompt\u001b[38;5;241m=\u001b[39mfew_shot_template,\n\u001b[0;32m     31\u001b[0m     memory\u001b[38;5;241m=\u001b[39mmemory,\n\u001b[0;32m     32\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     33\u001b[0m )\n",
      "File \u001b[1;32md:\\FULLSTACK-GPT\\env\\Lib\\site-packages\\langchain\\load\\serializable.py:97\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 97\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lc_kwargs \u001b[38;5;241m=\u001b[39m kwargs\n",
      "File \u001b[1;32md:\\FULLSTACK-GPT\\env\\Lib\\site-packages\\pydantic\\main.py:341\u001b[0m, in \u001b[0;36mpydantic.main.BaseModel.__init__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValidationError\u001b[0m: 1 validation error for FewShotPromptTemplate\nexample_prompt\n  value is not a valid dict (type=type_error.dict)"
     ]
    }
   ],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "from langchain.prompts import FewShotPromptTemplate\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage, AIMessage\n",
    "\n",
    "# LLM ì´ˆê¸°í™” (OpenAI ì˜ˆì œ)\n",
    "llm = ChatOpenAI(temperature=0.7)  # ì ì ˆí•œ LLM ì„¤ì •\n",
    "\n",
    "# ë©”ëª¨ë¦¬ ì´ˆê¸°í™”\n",
    "memory = ConversationBufferMemory()\n",
    "\n",
    "# FewShotPromptTemplate ì˜ˆì œ ì •ì˜\n",
    "examples = [\n",
    "    {\"input\": \"Top Gun\", \"output\": \"ğŸ›©ï¸ğŸ‘¨â€âœˆï¸ğŸ”¥\"},\n",
    "    {\"input\": \"The Godfather\", \"output\": \"ğŸ‘¨â€ğŸ‘¨â€ğŸ‘¦ğŸ”«ğŸ\"}\n",
    "]\n",
    "\n",
    "# FewShotPromptTemplate ì •ì˜\n",
    "few_shot_template = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    input_variables=[\"input\"],  # ì‚¬ìš©í•  ì…ë ¥ ë³€ìˆ˜ ì •ì˜\n",
    "    example_prompt=\"{input}: {output}\",\n",
    "    suffix=\"Input: {input}\\nOutput:\"\n",
    ")\n",
    "\n",
    "# ConversationChain ìƒì„±\n",
    "chain = ConversationChain(\n",
    "    llm=llm,  # ì ì ˆí•œ LLM ì—°ê²°\n",
    "    prompt=few_shot_template,\n",
    "    memory=memory,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# ì²´ì¸ í…ŒìŠ¤íŠ¸\n",
    "response1 = chain.run(\"The Matrix\")\n",
    "print(\"Response 1:\", response1)\n",
    "\n",
    "response2 = chain.run(\"Titanic\")\n",
    "print(\"Response 2:\", response2)\n",
    "\n",
    "# ì²« ë²ˆì§¸ ì˜í™”ê°€ ë¬´ì—‡ì´ì—ˆëŠ”ì§€ í™•ì¸\n",
    "memory_check = chain.memory.load_memory_variables({})\n",
    "print(\"Memory Check:\", memory_check)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
